{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e manipulação inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos Dados\n",
    "df_backstreetboys = pd.read_csv('Dados\\Backstreet_Boys_Lyrics_score.csv') \n",
    "df_backstreetboys = df_backstreetboys.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"]) # Remove colunas desnecessárias\n",
    "\n",
    "df_arcticmonkeys = pd.read_csv('Dados\\lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arctic Monkeys Dataframe\n",
    "df_arcticmonkeys.rename(columns={'lyrics': 'Lyrics'}, inplace=True) # Renomeia a coluna lyrics para Lyrics\n",
    "df_arcticmonkeys.drop(columns=['name', 'album'], inplace=True) # Remove colunas desnecessárias\n",
    "df_arcticmonkeys['Artist'] = 'Arctic Monkeys' # Adiciona a coluna Artist com o nome do artista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backstreet Boys Dataframe\n",
    "df_backstreetboys.drop(columns=['index','Album','Type of Album', 'Year of Release', 'Title','Duration(minutes:seconds)', 'Positive', 'Negative', 'Neutral', 'Compound'], inplace=True) # Remove colunas desnecessárias\n",
    "df_backstreetboys['Artist'] = 'Backstreet Boys' # Adiciona a coluna Artist com o nome do artista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide o dataset em teste e treino, um para cada banda\n",
    "df_bb_treino = df_backstreetboys.iloc[:50] # Seleciona as primeiras linhas do dataset\n",
    "df_bb_teste = df_backstreetboys.iloc[50:100] # Seleciona as últimas linhas do dataset\n",
    "\n",
    "df_am_treino = df_arcticmonkeys.iloc[:50] # Seleciona as primeiras linhas do dataset\n",
    "df_am_teste = df_arcticmonkeys.iloc[50:100] # Seleciona as últimas linhas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os dois dataframes\n",
    "df_am_bb = pd.concat([df_bb_teste, df_am_teste], ignore_index=True)\n",
    "df_am_bb = df_am_bb[['Artist', 'Lyrics']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidades de cada banda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade da palavra ser de cada banda\n",
    "p_am = len(df_am_treino) / (len(df_am_treino) + len(df_bb_treino))\n",
    "p_bb = len(df_bb_treino) / (len(df_am_treino) + len(df_bb_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de limpeza de texto\n",
    "palavras_inuteis = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z', 'and', 'or', 'and','me','he','him','himself','she','her','herself','we','our','ourself', 'the','they','them','themselves','to', 'you','your','yourself','yourselves','it',\n",
    "'its','itself','what','which','who','whom','this','that','these','those','am','is','are','was','were','been','being','have','has','had','having','do','does','did','doing','will','would','should', 'ya','can','re', 'oh','could','ought','im','youre','hes','shes','its','were','theyre','ive','youve','weve','theyve','id','youd','hed','shed','wed','theyd','ill','youll','hell','shell','well','theyll','isnt','arent','wasnt','werent','hasnt','havent','hadnt','doesnt','dont','didnt','wont','wouldnt','shant','shouldnt','cant','cannot','couldnt','mustnt','lets','thats','whos','whats','heres','theres','whens','wheres','whys','hows','a','an','the','and','but','if','or','because','as','until','while','of','at','by','for','with','about','against','between','into','through','during','before','after','above','below','to','from','up','upon','down','in','out','on','off','over','under','again','further','then','once','here','there','when','where','why','how','all','any','both',\n",
    "'each','few','more','most','other','some','such','no','nor','not','only','own','same','so','than','too','very','can','will','just','don','should','now','ve','1','2','3','4','5','6','7','8','9','0']\n",
    "\n",
    "def separador_palavra(text):\n",
    "    return text.split() # Separa o texto em palavras a partir dos espaços\n",
    "\n",
    "def limpar_musica(musica):\n",
    "    musica = musica.lower()\n",
    "    caracteres_a_remover = [',', '.', '?', '!', '(', ')', ';', ':', '\"', \"'\", '-', '[', ']', '\\r\\n', 'verse', 'chorus', '1', '2', '&']\n",
    "\n",
    "    for caractere in caracteres_a_remover:\n",
    "        musica = musica.replace(caractere, ' ')\n",
    "\n",
    "    return musica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de cada palavra aparecer dado que é Arctic Monkeys\n",
    "dict_am = {}\n",
    "dict_palavras_am = {}\n",
    "\n",
    "for musica_am in df_am_treino['Lyrics']:\n",
    "    musica_am = limpar_musica(musica_am) # Aplica a função limpar_musica a cada linha da coluna lyrics\n",
    "    dict_am['palavras'] = [palavra for palavra in separador_palavra(musica_am) if palavra not in palavras_inuteis]\n",
    "\n",
    "    df_am_novo = pd.DataFrame(dict_am)\n",
    "    palavras_am = df_am_novo['palavras'].explode() # Transforma a coluna palavras em um novo df para calcular a frequência de cada palavra corretamente\n",
    "\n",
    "    palavras_unicas_am = palavras_am.unique() # Remove palavras repetidas\n",
    "\n",
    "    for palavra_am in palavras_unicas_am:\n",
    "        if palavra_am not in dict_palavras_am:\n",
    "            dict_palavras_am[palavra_am] = 1\n",
    "        else:\n",
    "            dict_palavras_am[palavra_am] += 1\n",
    "\n",
    "dict_prob_am = {}\n",
    "\n",
    "for palavra_am in dict_palavras_am:\n",
    "    dict_prob_am[palavra_am] = dict_palavras_am[palavra_am] / len(df_am_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de cada palavra aparecer dado que é Backstreets Boys\n",
    "dict_bb = {}\n",
    "dict_palavras_bb = {}\n",
    "\n",
    "for musica_bb in df_bb_treino['Lyrics']:\n",
    "    musica_bb = limpar_musica(musica_bb) # Aplica a função limpar_musica a cada linha da coluna lyrics\n",
    "    dict_bb['palavras'] = [palavra for palavra in separador_palavra(musica_bb) if palavra not in palavras_inuteis]\n",
    "\n",
    "    df_bb_novo = pd.DataFrame(dict_bb)\n",
    "    palavras_bb = df_bb_novo['palavras'].explode() # Transforma a coluna palavras em um novo df para calcular a frequência de cada palavra corretamente\n",
    "\n",
    "    palavras_unicas_bb = palavras_bb.unique() # Remove palavras repetidas\n",
    "\n",
    "    for palavra_bb in palavras_unicas_bb:\n",
    "        if palavra_bb not in dict_palavras_bb:\n",
    "            dict_palavras_bb[palavra_bb] = 1\n",
    "        else:\n",
    "            dict_palavras_bb[palavra_bb] += 1\n",
    "\n",
    "dict_prob_bb = {}\n",
    "\n",
    "for palavra_bb in dict_palavras_bb:\n",
    "    dict_prob_bb[palavra_bb] = dict_palavras_bb[palavra_bb] / len(df_bb_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de cada palavra aparecer em ambas as bandas\n",
    "dict_palavras_both = {}\n",
    "\n",
    "for palavra_am_new in dict_palavras_am:\n",
    "    dict_palavras_both[palavra_am_new] = dict_palavras_am[palavra_am_new]\n",
    "\n",
    "for palavra_bb_new in dict_palavras_bb:\n",
    "    if palavra_bb_new not in dict_palavras_both:\n",
    "        dict_palavras_both[palavra_bb_new] = dict_palavras_bb[palavra_bb_new]\n",
    "    else:\n",
    "        dict_palavras_both[palavra_bb_new] += dict_palavras_bb[palavra_bb_new]\n",
    "\n",
    "dict_prob_both = {}\n",
    "\n",
    "for palavra_both in dict_palavras_both:\n",
    "    dict_prob_both[palavra_both] = dict_palavras_both[palavra_both] / (len(df_am_treino) + len(df_bb_treino))\n",
    "\n",
    "# Probabilidade cada palavra NÃO aparecer em cada banda\n",
    "dict_prob_nao_both = {}\n",
    "\n",
    "for palavra_both in dict_palavras_both:\n",
    "    dict_prob_nao_both[palavra_both] = 1 - dict_prob_both[palavra_both]\n",
    "\n",
    "dict_prob_nao_am = {}\n",
    "\n",
    "for palavra_am in dict_palavras_both:\n",
    "    if palavra_am not in dict_prob_am:\n",
    "        dict_prob_nao_am[palavra_am] = 1 \n",
    "    else:\n",
    "        dict_prob_nao_am[palavra_am] = 1 - dict_prob_am[palavra_am]\n",
    "\n",
    "dict_prob_nao_bb = {}\n",
    "\n",
    "for palavra_bb in dict_palavras_both:\n",
    "    if palavra_bb not in dict_prob_bb:\n",
    "        dict_prob_nao_bb[palavra_bb] = 1 \n",
    "    else:\n",
    "        dict_prob_nao_bb[palavra_bb] = 1 - dict_prob_bb[palavra_bb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "acertos = 0\n",
    "def classificador(musica, dict_prob_both, dict_prob_am, dict_prob_bb):\n",
    "    prob_am = 0\n",
    "    prob_bb = 0\n",
    "    nova_musica = []\n",
    "    \n",
    "    musica_limpa = limpar_musica(musica)\n",
    "    nova_musica = separador_palavra(musica_limpa)\n",
    "\n",
    "    for palavra in nova_musica:\n",
    "        if palavra not in dict_palavras_both:\n",
    "            continue\n",
    "        if palavra not in dict_prob_am:\n",
    "            prob_am += (log((dict_prob_nao_am[palavra] / dict_prob_nao_both[palavra])))\n",
    "        if palavra not in dict_prob_bb:\n",
    "            prob_bb += (log((dict_prob_nao_bb[palavra] / dict_prob_nao_both[palavra])))\n",
    "        if palavra in dict_prob_am:\n",
    "            prob_am += (log((dict_prob_am[palavra] / dict_prob_both[palavra])))\n",
    "        if palavra in dict_prob_bb:\n",
    "            prob_bb += (log((dict_prob_bb[palavra] / dict_prob_both[palavra])))\n",
    "\n",
    "    prob_am += log(0.5)\n",
    "    prob_bb += log(0.5)\n",
    "    \n",
    "    if prob_am > prob_bb:\n",
    "        return 'Arctic Monkeys'\n",
    "    else: \n",
    "        return 'Backstreet Boys'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A accuracy é de 82%\n"
     ]
    }
   ],
   "source": [
    "acertos = 0\n",
    "for i in range(100):\n",
    "    \n",
    "    linha = df_am_bb.iloc[randint(0, (len(df_am_bb)-1))]\n",
    "    letra, banda = linha['Lyrics'] , linha['Artist']\n",
    "    musica = classificador(letra, dict_prob_both, dict_prob_am, dict_prob_bb)\n",
    "    if musica == banda:\n",
    "        acertos +=1\n",
    "print(f'A accuracy é de {acertos}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
