{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_backstreetboys = pd.read_csv('Dados\\Backstreet_Boys_Lyrics_score.csv') \n",
    "df_backstreetboys = df_backstreetboys.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"]) # Remove colunas desnecessárias\n",
    "\n",
    "df_arcticmonkeys = pd.read_csv('Dados\\lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide o dataset em 2, um para cada banda\n",
    "df_bb_treino = df_backstreetboys.iloc[:50] # Seleciona as primeiras linhas do dataset\n",
    "df_bb_teste = df_backstreetboys.iloc[50:100] # Seleciona as últimas linhas do dataset\n",
    "\n",
    "df_am_treino = df_arcticmonkeys.iloc[:50] # Seleciona as primeiras linhas do dataset\n",
    "df_am_teste = df_arcticmonkeys.iloc[50:100] # Seleciona as últimas linhas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de ser de cada banda\n",
    "\n",
    "p_am = len(df_am_treino) / (len(df_am_treino) + len(df_bb_treino))\n",
    "p_bb = len(df_bb_treino) / (len(df_am_treino) + len(df_bb_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "palavras_inuteis = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z', 'and', 'or', 'and','me','he','him','himself','she','her','herself','we','our','ourself', 'the','they','them','themselves','to', 'you','your','yourself','yourselves','it',\n",
    "'its','itself','what','which','who','whom','this','that','these','those','am','is','are','was','were','been','being','have','has','had','having','do','does','did','doing','will','would','should', 'ya','can','re', 'oh','could','ought','im','youre','hes','shes','its','were','theyre','ive','youve','weve','theyve','id','youd','hed','shed','wed','theyd','ill','youll','hell','shell','well','theyll','isnt','arent','wasnt','werent','hasnt','havent','hadnt','doesnt','dont','didnt','wont','wouldnt','shant','shouldnt','cant','cannot','couldnt','mustnt','lets','thats','whos','whats','heres','theres','whens','wheres','whys','hows','a','an','the','and','but','if','or','because','as','until','while','of','at','by','for','with','about','against','between','into','through','during','before','after','above','below','to','from','up','upon','down','in','out','on','off','over','under','again','further','then','once','here','there','when','where','why','how','all','any','both',\n",
    "'each','few','more','most','other','some','such','no','nor','not','only','own','same','so','than','too','very','can','will','just','don','should','now','ve','1','2','3','4','5','6','7','8','9','0']\n",
    "\n",
    "def separador_palavra(text):\n",
    "    return text.split() # Separa o texto em palavras a partir dos espaços\n",
    "\n",
    "def limpar_musica(musica_am):\n",
    "    musica_am = musica_am.lower()\n",
    "    caracteres_a_remover = [',', '.', '?', '!', '(', ')', ';', ':', '\"', \"'\", '-', '[', ']', '\\r\\n', 'verse', 'chorus', '1', '2', '&']\n",
    "\n",
    "    for caractere in caracteres_a_remover:\n",
    "        musica_am = musica_am.replace(caractere, ' ')\n",
    "\n",
    "    return musica_am\n",
    "\n",
    "\n",
    "# Probabilidade de cada palavra aparecer dado que é Arctic Monkeys\n",
    "dict_am = {}\n",
    "dict_palavras_am = {}\n",
    "\n",
    "for musica_am in df_am_treino['lyrics']:\n",
    "    musica_am = limpar_musica(musica_am) # Aplica a função limpar_musica a cada linha da coluna lyrics\n",
    "    # dict_am['palavras'] = separador_palavra(musica_am) # Aplica a função separador_palavra a cada linha da coluna lyrics\n",
    "    dict_am['palavras'] = [palavra for palavra in separador_palavra(musica_am) if palavra not in palavras_inuteis]\n",
    "\n",
    "    df_am_novo = pd.DataFrame(dict_am)\n",
    "    palavras_am = df_am_novo['palavras'].explode() # Transforma a coluna palavras em um novo df para calcular a frequência de cada palavra corretamente\n",
    "\n",
    "    palavras_unicas_am = palavras_am.unique() # Remove palavras repetidas\n",
    "\n",
    "    for palavra_am in palavras_unicas_am:\n",
    "        if palavra_am not in dict_palavras_am:\n",
    "            dict_palavras_am[palavra_am] = 1\n",
    "        else:\n",
    "            dict_palavras_am[palavra_am] += 1\n",
    "\n",
    "dict_prob_am = {}\n",
    "\n",
    "for palavra_am in dict_palavras_am:\n",
    "    dict_prob_am[palavra_am] = dict_palavras_am[palavra_am] / len(df_am_treino)\n",
    "\n",
    "dict_prob_nao_am = {}\n",
    "\n",
    "for palavra_am in dict_palavras_am:\n",
    "    dict_prob_nao_am[palavra_am] = 1 - dict_prob_am[palavra_am]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de cada palavra aparecer em Backstreets Boys\n",
    "dict_bb = {}\n",
    "dict_palavras_bb = {}\n",
    "\n",
    "for musica_bb in df_bb_treino['Lyrics']:\n",
    "    musica_bb = limpar_musica(musica_bb)\n",
    "    dict_bb['palavras'] = separador_palavra(musica_bb) # Aplica a função separador_palavra a cada linha da coluna lyrics\n",
    "    df_bb_novo = pd.DataFrame(dict_bb)\n",
    "    palavras_bb = df_bb_novo['palavras'].explode() # Transforma a coluna palavras em um novo df para calcular a frequência de cada palavra corretamente\n",
    "\n",
    "    palavras_unicas_bb = palavras_bb.unique() # Remove palavras repetidas\n",
    "\n",
    "    for palavra_bb in palavras_unicas_bb:\n",
    "        if palavra_bb not in dict_palavras_bb:\n",
    "            dict_palavras_bb[palavra_bb] = 1\n",
    "        else:\n",
    "            dict_palavras_bb[palavra_bb] += 1\n",
    "\n",
    "dict_prob_bb = {}\n",
    "\n",
    "for palavra_bb in dict_palavras_bb:\n",
    "    dict_prob_bb[palavra_bb] = dict_palavras_bb[palavra_bb] / len(df_bb_treino)\n",
    "\n",
    "dict_prob_nao_bb = {}\n",
    "\n",
    "for palavra_bb in dict_palavras_bb:\n",
    "    dict_prob_nao_bb[palavra_bb] = 1 - dict_prob_bb[palavra_bb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de cada palavra aparecer em ambas as bandas\n",
    "dict_palavras_both = {}\n",
    "\n",
    "for palavra_am_new in dict_palavras_am:\n",
    "    dict_palavras_both[palavra_am_new] = dict_palavras_am[palavra_am_new]\n",
    "\n",
    "for palavra_bb_new in dict_palavras_bb:\n",
    "    if palavra_bb_new not in dict_palavras_both:\n",
    "        dict_palavras_both[palavra_bb_new] = dict_palavras_bb[palavra_bb_new]\n",
    "    else:\n",
    "        dict_palavras_both[palavra_bb_new] += dict_palavras_bb[palavra_bb_new]\n",
    "\n",
    "dict_prob_both = {}\n",
    "\n",
    "for palavra_both in dict_palavras_both:\n",
    "    dict_prob_both[palavra_both] = dict_palavras_both[palavra_both] / (len(df_am_treino) + len(df_bb_treino))\n",
    "\n",
    "dict_prob_nao_both = {}\n",
    "\n",
    "for palavra_both in dict_palavras_both:\n",
    "    dict_prob_nao_both[palavra_both] = 1 - dict_prob_both[palavra_both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de ser do Arctic Monkeys dado que a palavra aparece\n",
    "dict_prob_am_dado_palavra = {}\n",
    "\n",
    "for palavra in dict_prob_am:\n",
    "    dict_prob_am_dado_palavra[palavra] = (dict_prob_am[palavra] * p_am) / dict_prob_both[palavra]\n",
    "\n",
    "# Probabilidade de ser do Backstreet Boys dado que a palavra aparece\n",
    "dict_prob_bb_dado_palavra = {}\n",
    "\n",
    "for palavra in dict_prob_bb:\n",
    "    dict_prob_bb_dado_palavra[palavra] = (dict_prob_bb[palavra] * p_bb) / dict_prob_both[palavra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "def classificador(musica, dict_prob_both, dict_prob_am, dict_prob_bb):\n",
    "    prob_am = 0\n",
    "    prob_bb = 0\n",
    "    # musica = limpar_musica(musica)\n",
    "\n",
    "    for palavra in musica:\n",
    "        if palavra not in dict_prob_both or palavra not in dict_prob_am:\n",
    "            prob_am *= (dict_prob_nao_am[palavra] / dict_prob_nao_both[palavra]) * p_am\n",
    "        if palavra not in dict_prob_both or palavra not in dict_prob_bb:\n",
    "            prob_bb *= (dict_prob_nao_bb[palavra] / dict_prob_nao_both[palavra]) * p_bb\n",
    "        if palavra in dict_prob_both or palavra in dict_prob_am:\n",
    "            prob_am *= (dict_prob_am[palavra] / dict_prob_both[palavra]) * p_am\n",
    "        if palavra in dict_prob_both or palavra in dict_prob_bb:\n",
    "            prob_bb *= (dict_prob_bb[palavra] / dict_prob_both[palavra]) * p_bb\n",
    "    \n",
    "    if prob_am > prob_bb:\n",
    "        return 'Arctic Monkeys'\n",
    "    else: \n",
    "        return 'Backstreet Boys'\n",
    "    \n",
    "musica = classificador('wanna be yours', dict_prob_both, dict_prob_am, dict_prob_bb)\n",
    "musica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
